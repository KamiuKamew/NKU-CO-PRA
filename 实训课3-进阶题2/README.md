# 进阶题 2：基于 MLP 的低轨卫星网络带宽预测性能优化挑战

## 🎯 项目概述

本项目实现了基于多层感知机(MLP)的低轨卫星网络带宽预测系统，支持完整的深度学习训练流程，包括前向传播、反向传播、梯度下降优化，并使用 DCU 硬件加速实现高性能训练和推理。

### 核心功能

- ✅ **完整 MLP 实现**：前向传播、反向传播、梯度下降训练
- ✅ **时间序列预测**：基于滑动窗口的带宽预测（10→1 预测模式）
- ✅ **DCU 硬件加速**：全流程 HIP 并行计算优化
- ✅ **数据处理管道**：JSON 数据加载、归一化、数据集构建
- ✅ **性能评测系统**：训练时间、推理延迟、预测精度评估
- ✅ **CPU/DCU 对比**：完整的性能基准测试

## 📁 项目结构

```
实训课3-进阶题2/
├── inst_manual/           # 任务说明文档
│   ├── readme.md         # 任务需求文档
│   └── fig.png           # 反向传播示意图
├── data/                 # 数据文件
│   └── starlink_bw.json  # 低轨卫星带宽数据
├── src/                  # 源代码
│   ├── sourcefile_mlp.cpp    # 原始模板文件
│   └── mlp_dcu.cpp          # DCU完整实现
├── compare_cpu.cpp       # CPU基准版本
├── compile_dcu.sh        # DCU编译脚本
├── run_test.sh          # 性能测试脚本
├── compare_performance.sh # 性能对比脚本
└── README.md            # 项目说明文档
```

## 🚀 快速开始

### 环境要求

- **DCU 环境**：支持 ROCm/HIP 的 AMD DCU
- **编译器**：hipcc (DCU 版本) 或 g++ (CPU 版本)
- **数据**：starlink_bw.json 带宽数据文件

### 编译和运行

#### 1. DCU 版本（推荐）

```bash
# 编译DCU版本
./compile_dcu.sh

# 运行性能测试
./run_test.sh
```

#### 2. CPU 基准版本

```bash
# 编译CPU版本
g++ -O3 -std=c++14 compare_cpu.cpp -o mlp_cpu

# 运行CPU测试
./mlp_cpu
```

#### 3. 性能对比测试

```bash
# 同时运行CPU和DCU版本进行对比
./compare_performance.sh
```

## 🏗️ 技术架构

### 网络结构

- **输入层**：10 个神经元（滑动窗口大小）
- **隐藏层**：64 个神经元 + ReLU 激活
- **输出层**：1 个神经元（预测下一时刻带宽）
- **训练参数**：批大小 128，学习率 0.001，训练轮数 500

### DCU 优化策略

1. **并行矩阵运算**：16×16 线程块优化
2. **内存管理**：统一内存分配和数据传输
3. **HIP 内核融合**：偏置加法、激活函数内核优化
4. **梯度计算**：并行反向传播实现
5. **批量处理**：高效的批次数据处理

### 数据处理流程

1. **数据加载**：JSON 格式带宽序列读取
2. **数据归一化**：Min-Max 标准化 [0,1]
3. **滑动窗口**：N=10 的时间序列样本构建
4. **数据集划分**：训练集 80%，测试集 20%

## 📊 性能评测指标

### 训练性能

- 训练时间（毫秒）
- 每秒样本处理数
- 损失收敛曲线

### 推理性能

- 推理延迟（毫秒）
- 推理吞吐量（样本/秒）
- 内存使用效率

### 预测精度

- 均方误差（MSE）
- 平均绝对误差（MAE）
- 预测趋势匹配度

## 🔧 使用示例

### 基本训练和推理

```bash
cd 实训课3-进阶题2

# 编译DCU版本
./compile_dcu.sh

# 运行完整测试
./run_test.sh
```

### 性能对比测试

```bash
# 运行CPU vs DCU性能对比
./compare_performance.sh

# 查看详细结果
cat performance_comparison.txt
```

### 自定义参数

修改 `src/mlp_dcu.cpp` 中的宏定义：

```cpp
#define INPUT_DIM 10        // 滑动窗口大小
#define HIDDEN_DIM 64       // 隐藏层神经元数
#define BATCH_SIZE 128      // 批处理大小
#define EPOCHS 500          // 训练轮数
#define LEARNING_RATE 0.001 // 学习率
```

## 📈 预期性能结果

### 数据规模

- **数据点数量**：~3000 个时间序列点
- **训练样本**：~2400 个样本
- **测试样本**：~600 个样本

### 性能基准（参考值）

| 指标       | CPU 基准    | DCU 加速    | 加速比 |
| ---------- | ----------- | ----------- | ------ |
| 训练时间   | ~5000ms     | ~2000ms     | 2.5x   |
| 推理时间   | ~50ms       | ~20ms       | 2.5x   |
| 推理吞吐量 | 200 样本/秒 | 500 样本/秒 | 2.5x   |
| 预测精度   | MSE<0.01    | MSE<0.01    | 相当   |

## 🛠️ 故障排除

### 编译问题

1. **HIP 头文件缺失**：确保安装 ROCm 开发环境
2. **hipcc 未找到**：检查 PATH 环境变量
3. **链接错误**：验证 HIP 库路径配置

### 运行时问题

1. **数据文件缺失**：确保`data/starlink_bw.json`存在
2. **内存不足**：减小 BATCH_SIZE 或 HIDDEN_DIM
3. **DCU 不可用**：使用 CPU 版本进行测试

### 性能调优

1. **增大批大小**：提高并行度（需要更多内存）
2. **调整网络结构**：增加隐藏层神经元数
3. **优化线程块配置**：修改 HIP 内核参数

## 📋 实验任务完成清单

- [x] **MLP 网络实现**：完整的前向和反向传播
- [x] **DCU 硬件加速**：HIP 并行计算优化
- [x] **训练系统**：梯度下降和参数更新
- [x] **数据处理**：JSON 加载和时间序列构建
- [x] **性能评测**：训练和推理性能测试
- [x] **结果对比**：CPU vs DCU 性能分析
- [x] **文档完善**：技术报告和使用说明

## 🎓 技术创新点

1. **完整训练流程**：从零实现包含反向传播的深度学习系统
2. **HIP 并行优化**：全流程 DCU 加速实现
3. **时间序列建模**：针对卫星带宽预测的专门优化
4. **性能基准框架**：可扩展的性能评测体系
5. **跨平台对比**：CPU 和 DCU 的全面性能分析

## 📞 技术支持

如遇到问题，请检查：

1. 系统环境配置（ROCm/HIP）
2. 数据文件完整性
3. 编译参数和依赖库
4. 硬件资源可用性

---

**项目完成时间**：2024 年

**技术栈**：C++ + HIP + DCU + 机器学习

**应用领域**：低轨卫星网络、时间序列预测、高性能计算
